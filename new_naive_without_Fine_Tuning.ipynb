{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 93282,
          "databundleVersionId": 11098970,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 104449,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 68809,
          "modelId": 91102
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "new_naive_without_Fine-Tuning",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahesh-ishran/Multi-Lingual-Sentiment-Analysis/blob/main/new_naive_without_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "ZaI_AFdTseC4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "multi_lingual_sentiment_analysis_path = kagglehub.competition_download('multi-lingual-sentiment-analysis')\n",
        "metaresearch_llama_3_1_transformers_8b_instruct_2_path = kagglehub.model_download('metaresearch/llama-3.1/Transformers/8b-instruct/2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dpVpDBSTseC4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:17.34621Z",
          "iopub.execute_input": "2025-02-18T01:28:17.34646Z",
          "iopub.status.idle": "2025-02-18T01:28:17.663321Z",
          "shell.execute_reply.started": "2025-02-18T01:28:17.346424Z",
          "shell.execute_reply": "2025-02-18T01:28:17.662512Z"
        },
        "id": "lvMWcVcNseC5",
        "outputId": "b8b2a347-7714-483f-b39f-519b8252fe04"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n/kaggle/input/multi-lingual-sentiment-analysis/sample_submission.csv\n/kaggle/input/multi-lingual-sentiment-analysis/train.csv\n/kaggle/input/multi-lingual-sentiment-analysis/test.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install transformers peft datasets accelerate sentencepiece\n",
        "# !pip install torch==2.6.0"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:17.664095Z",
          "iopub.execute_input": "2025-02-18T01:28:17.664449Z",
          "iopub.status.idle": "2025-02-18T01:28:17.667996Z",
          "shell.execute_reply.started": "2025-02-18T01:28:17.664395Z",
          "shell.execute_reply": "2025-02-18T01:28:17.667022Z"
        },
        "id": "3BGSAEikseC6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:17.668888Z",
          "iopub.execute_input": "2025-02-18T01:28:17.669147Z",
          "iopub.status.idle": "2025-02-18T01:28:29.343532Z",
          "shell.execute_reply.started": "2025-02-18T01:28:17.669108Z",
          "shell.execute_reply": "2025-02-18T01:28:29.342641Z"
        },
        "id": "m3-B6P5PseC6",
        "outputId": "00307000-ca08-4b8d-b946-7a14d13e5ea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "2.17.1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:29.345284Z",
          "iopub.execute_input": "2025-02-18T01:28:29.345741Z",
          "iopub.status.idle": "2025-02-18T01:28:35.994936Z",
          "shell.execute_reply.started": "2025-02-18T01:28:29.345718Z",
          "shell.execute_reply": "2025-02-18T01:28:35.993856Z"
        },
        "id": "e-Ha2FLbseC7",
        "outputId": "010a52f4-27ca-4657-8e6f-ae5fce46b6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.2-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchvision"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:35.996925Z",
          "iopub.execute_input": "2025-02-18T01:28:35.997292Z",
          "iopub.status.idle": "2025-02-18T01:28:36.000884Z",
          "shell.execute_reply.started": "2025-02-18T01:28:35.997258Z",
          "shell.execute_reply": "2025-02-18T01:28:36.000019Z"
        },
        "id": "TioVmgNOseC7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer,BitsAndBytesConfig,pipeline\n",
        "from datasets import load_dataset,DatasetDict,Dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:36.001766Z",
          "iopub.execute_input": "2025-02-18T01:28:36.001967Z",
          "iopub.status.idle": "2025-02-18T01:28:46.438678Z",
          "shell.execute_reply.started": "2025-02-18T01:28:36.001942Z",
          "shell.execute_reply": "2025-02-18T01:28:46.437992Z"
        },
        "id": "JqfzsQR8seC7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (accuracy_score,\n",
        "                             classification_report,\n",
        "                             confusion_matrix,f1_score)\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:30:53.092156Z",
          "iopub.execute_input": "2025-02-18T01:30:53.092497Z",
          "iopub.status.idle": "2025-02-18T01:30:53.096524Z",
          "shell.execute_reply.started": "2025-02-18T01:30:53.092471Z",
          "shell.execute_reply": "2025-02-18T01:30:53.095589Z"
        },
        "id": "yMnRlB-YseC7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"working on {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.453671Z",
          "iopub.execute_input": "2025-02-18T01:28:46.453954Z",
          "iopub.status.idle": "2025-02-18T01:28:46.530252Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.453926Z",
          "shell.execute_reply": "2025-02-18T01:28:46.529501Z"
        },
        "id": "S7RZiNupseC8",
        "outputId": "d7e41131-07d1-4be2-85cf-351c702a4477"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "working on cuda:0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/kaggle/input/multi-lingual-sentiment-analysis/train.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.531068Z",
          "iopub.execute_input": "2025-02-18T01:28:46.53132Z",
          "iopub.status.idle": "2025-02-18T01:28:46.599983Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.531289Z",
          "shell.execute_reply": "2025-02-18T01:28:46.59917Z"
        },
        "id": "AunMEbIDseC8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['language']=='bd']['sentence'][8]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.601047Z",
          "iopub.execute_input": "2025-02-18T01:28:46.601373Z",
          "iopub.status.idle": "2025-02-18T01:28:46.615673Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.601342Z",
          "shell.execute_reply": "2025-02-18T01:28:46.614922Z"
        },
        "id": "CNiKHD1LseC8",
        "outputId": "84d4b268-6f46-4d0e-ec0e-2862fc5a1971"
      },
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'लेन्सा मैला हाबहोनो हायै रोखोमै आरो दागो होबथाहानाय महरै बानायजानाय नङा।'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "unique_languages_df = data.drop_duplicates(subset=['language'])\n",
        "unique_languages_df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.61637Z",
          "iopub.execute_input": "2025-02-18T01:28:46.61667Z",
          "iopub.status.idle": "2025-02-18T01:28:46.6411Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.616644Z",
          "shell.execute_reply": "2025-02-18T01:28:46.640469Z"
        },
        "id": "9NElyG_jseC8",
        "outputId": "37c12b3b-f3b5-4574-d25c-56ecdfa2d055"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    ID                                           sentence     label language\n0    1  কর্মীদের ভাল আচরণ এবং খাবারের পাশাপাশি পানীয় ...  Positive       bn\n1    2  ગોદરેજ સેન્ટ્રલ એસીમાં તેના કન્ડેન્સર પર 2 વર્...  Positive       gu\n2    3  கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும்...  Positive       ta\n3    4  ਵੌਇਸ-ਓਵਰ ਬਹੁਤ ਵਧੀਆ ਸੀ ਅਤੇ ਕਹਾਣੀ ਦੀ ਸੀਮਾ ਵਿੱਚ ਇ...  Positive       pa\n4    5  जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जाय...  Negative       bd\n5    6  ইয়াত বহুতো জনপ্ৰিয় কিতাপ বিনামূলীয়াকৈ উপলব্...  Positive       as\n6    7  సింఫనీ పర్సనల్ ఎయిర్ కూలర్ ఇప్పుడు హ్యుమిడిటీ ...  Positive       te\n11  12  କ୍ଷୁଦ୍ର ସ୍ଥାନଗୁଡ଼ିକ ପାଇଁ ଏବଂ ସ୍ୱଳ୍ପ ଇଣ୍ଟରିୟର ପ...  Positive       or\n12  13  \"ഈ വില ശ്രേണിയിൽ കസേരകൾക്ക് ക്രമീകരിക്കാവുന്ന ...  Positive       ml\n13  14  \"चेयर कार में, अधिक चार्जिंग पॉइंट की आवश्यकता...  Negative       hi\n22  23  बेड असेंबल करायला सोपा आणि अतिशय आरामदायक आहे....  Positive       mr\n23  24  بالٹرا کا ٹیبل فین گھریلو استعمال کے لیے ہلکا ...  Positive       ur\n24  25  ಸರ್ವರ್‌ಗಳ ವಿನಮ್ರ ಮತ್ತು ಉತ್ತಮ ನಡವಳಿಕೆಯನ್ನು ನೀಡಿ...  Positive       kn",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>কর্মীদের ভাল আচরণ এবং খাবারের পাশাপাশি পানীয় ...</td>\n      <td>Positive</td>\n      <td>bn</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>ગોદરેજ સેન્ટ્રલ એસીમાં તેના કન્ડેન્સર પર 2 વર્...</td>\n      <td>Positive</td>\n      <td>gu</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>கதைக்களம் பிடித்திருந்தது, அனைத்து நடிகர்களும்...</td>\n      <td>Positive</td>\n      <td>ta</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>ਵੌਇਸ-ਓਵਰ ਬਹੁਤ ਵਧੀਆ ਸੀ ਅਤੇ ਕਹਾਣੀ ਦੀ ਸੀਮਾ ਵਿੱਚ ਇ...</td>\n      <td>Positive</td>\n      <td>pa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>जुथानि थाखाय जायगा गैया। गुबुन मुवा सोग्रा जाय...</td>\n      <td>Negative</td>\n      <td>bd</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>ইয়াত বহুতো জনপ্ৰিয় কিতাপ বিনামূলীয়াকৈ উপলব্...</td>\n      <td>Positive</td>\n      <td>as</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>సింఫనీ పర్సనల్ ఎయిర్ కూలర్ ఇప్పుడు హ్యుమిడిటీ ...</td>\n      <td>Positive</td>\n      <td>te</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>କ୍ଷୁଦ୍ର ସ୍ଥାନଗୁଡ଼ିକ ପାଇଁ ଏବଂ ସ୍ୱଳ୍ପ ଇଣ୍ଟରିୟର ପ...</td>\n      <td>Positive</td>\n      <td>or</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>\"ഈ വില ശ്രേണിയിൽ കസേരകൾക്ക് ക്രമീകരിക്കാവുന്ന ...</td>\n      <td>Positive</td>\n      <td>ml</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>\"चेयर कार में, अधिक चार्जिंग पॉइंट की आवश्यकता...</td>\n      <td>Negative</td>\n      <td>hi</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>बेड असेंबल करायला सोपा आणि अतिशय आरामदायक आहे....</td>\n      <td>Positive</td>\n      <td>mr</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>بالٹرا کا ٹیبل فین گھریلو استعمال کے لیے ہلکا ...</td>\n      <td>Positive</td>\n      <td>ur</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>25</td>\n      <td>ಸರ್ವರ್‌ಗಳ ವಿನಮ್ರ ಮತ್ತು ಉತ್ತಮ ನಡವಳಿಕೆಯನ್ನು ನೀಡಿ...</td>\n      <td>Positive</td>\n      <td>kn</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test=pd.read_csv('/kaggle/input/multi-lingual-sentiment-analysis/test.csv')\n",
        "test['language'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.641797Z",
          "iopub.execute_input": "2025-02-18T01:28:46.641989Z",
          "iopub.status.idle": "2025-02-18T01:28:46.677772Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.641973Z",
          "shell.execute_reply": "2025-02-18T01:28:46.677072Z"
        },
        "id": "ouXeo8coseC8",
        "outputId": "f6273dc7-facd-4fbd-d86b-35192d546226"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['pa', 'gu', 'kn', 'as', 'ur', 'te', 'ta', 'ml', 'bn', 'hi', 'or',\n       'bd', 'mr'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lang_mapping = {\n",
        "    'bn': 'Bangla',\n",
        "    'gu': 'Gujarati',\n",
        "    'ta': 'Tamil',\n",
        "    'pa': 'Punjabi',\n",
        "    'bd': 'Bodo',\n",
        "    'as': 'Assamese',\n",
        "    'te': 'Telugu',\n",
        "    'or': 'Odia',\n",
        "    'ml': 'Malayalam',\n",
        "    'hi': 'Hindi',\n",
        "    'mr': 'Marathi',\n",
        "    'ur': 'Urdu',\n",
        "    'kn': 'Kannada'\n",
        "}\n",
        "\n",
        "data['language'] = data['language'].replace(lang_mapping)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.680566Z",
          "iopub.execute_input": "2025-02-18T01:28:46.680756Z",
          "iopub.status.idle": "2025-02-18T01:28:46.688067Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.68074Z",
          "shell.execute_reply": "2025-02-18T01:28:46.687475Z"
        },
        "id": "jhVO-tfPseC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "data['language'].unique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.689608Z",
          "iopub.execute_input": "2025-02-18T01:28:46.689872Z",
          "iopub.status.idle": "2025-02-18T01:28:46.700726Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.689842Z",
          "shell.execute_reply": "2025-02-18T01:28:46.699935Z"
        },
        "id": "CWcZSU0TseC9",
        "outputId": "c8147d2c-b52a-4aab-aba8-d98b5a96da8b"
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array(['Bangla', 'Gujarati', 'Tamil', 'Punjabi', 'Bodo', 'Assamese',\n       'Telugu', 'Odia', 'Malayalam', 'Hindi', 'Marathi', 'Urdu',\n       'Kannada'], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = data[['sentence','label','language']]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.701585Z",
          "iopub.execute_input": "2025-02-18T01:28:46.701815Z",
          "iopub.status.idle": "2025-02-18T01:28:46.713966Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.701796Z",
          "shell.execute_reply": "2025-02-18T01:28:46.713269Z"
        },
        "id": "Jr0_3aWnseC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "print(\"Training set size:\", train_df.shape)\n",
        "print(\"Testing set size:\", test_df.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.714659Z",
          "iopub.execute_input": "2025-02-18T01:28:46.714942Z",
          "iopub.status.idle": "2025-02-18T01:28:46.728277Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.714921Z",
          "shell.execute_reply": "2025-02-18T01:28:46.727586Z"
        },
        "id": "V-J3iqqPseC9",
        "outputId": "2cc83849-346c-4ef3-df0e-e3e82f302025"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training set size: (900, 3)\nTesting set size: (100, 3)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset index for both train and test sets\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.729156Z",
          "iopub.execute_input": "2025-02-18T01:28:46.729346Z",
          "iopub.status.idle": "2025-02-18T01:28:46.740541Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.72933Z",
          "shell.execute_reply": "2025-02-18T01:28:46.739698Z"
        },
        "id": "Pd_JKPg3seC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(data_point):\n",
        "    return f\"\"\"\n",
        "            Analyze the sentiment of the sentence which is in language {data_point[\"language\"]} enclosed in square brackets ,\n",
        "            determine if it is positive or negative, and return the answer as\n",
        "            the corresponding sentiment label \"Positive\" or \"Negative\".\n",
        "            [{data_point[\"sentence\"]}] = {data_point[\"label\"]}\"\"\".strip()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.741235Z",
          "iopub.execute_input": "2025-02-18T01:28:46.741535Z",
          "iopub.status.idle": "2025-02-18T01:28:46.752102Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.741505Z",
          "shell.execute_reply": "2025-02-18T01:28:46.751361Z"
        },
        "id": "Nj_K4Nx8seC9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = pd.DataFrame(train_df.apply(generate_prompt, axis=1),\n",
        "                       columns=[\"sentence\"])\n",
        "x_eval = pd.DataFrame(test_df.apply(generate_prompt, axis=1),\n",
        "                      columns=[\"sentence\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.752896Z",
          "iopub.execute_input": "2025-02-18T01:28:46.753167Z",
          "iopub.status.idle": "2025-02-18T01:28:46.774596Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.753141Z",
          "shell.execute_reply": "2025-02-18T01:28:46.773936Z"
        },
        "id": "3cpwmexEseC-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x_train['sentence'][0]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.775362Z",
          "iopub.execute_input": "2025-02-18T01:28:46.775683Z",
          "iopub.status.idle": "2025-02-18T01:28:46.786928Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.775657Z",
          "shell.execute_reply": "2025-02-18T01:28:46.786268Z"
        },
        "id": "YD0VskRAseC-",
        "outputId": "42803d2d-7c63-4c0b-d9d6-2bb7a59d2257"
      },
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'Analyze the sentiment of the sentence which is in language Gujarati enclosed in square brackets , \\n            determine if it is positive or negative, and return the answer as \\n            the corresponding sentiment label \"Positive\" or \"Negative\".\\n            [વોલ્ટાસ સેન્ટ્રલ એસી જે સંયુક્ત બાષ્પીભવક સાથે આવે છે તે વધુ ઉર્જા કાર્યક્ષમ છે કારણ કે તે ઠંડક અને ગરમી બંને પ્રક્રિયાઓ માટે એક એકમનો ઉપયોગ કરે છે.] = Positive'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = Dataset.from_pandas(x_train)\n",
        "eval_data = Dataset.from_pandas(x_eval)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.787777Z",
          "iopub.execute_input": "2025-02-18T01:28:46.788017Z",
          "iopub.status.idle": "2025-02-18T01:28:46.813053Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.787999Z",
          "shell.execute_reply": "2025-02-18T01:28:46.812481Z"
        },
        "id": "BrosrtYjseC-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.813745Z",
          "iopub.execute_input": "2025-02-18T01:28:46.813952Z",
          "iopub.status.idle": "2025-02-18T01:28:46.818227Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.813934Z",
          "shell.execute_reply": "2025-02-18T01:28:46.817552Z"
        },
        "id": "Y6Tf08j_seC-",
        "outputId": "f8e640fe-a9d8-4ea9-dad6-9a76e5c98e1e"
      },
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['sentence'],\n    num_rows: 900\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.819072Z",
          "iopub.execute_input": "2025-02-18T01:28:46.81934Z",
          "iopub.status.idle": "2025-02-18T01:28:46.829376Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.81931Z",
          "shell.execute_reply": "2025-02-18T01:28:46.828758Z"
        },
        "id": "wwRyT0v0seC-",
        "outputId": "104e3767-69cf-42fc-ea20-50c85a77e8e5"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Dataset({\n    features: ['sentence'],\n    num_rows: 100\n})"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### x_test"
      ],
      "metadata": {
        "id": "EswAYSp5seC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 100  # Number of rows you want\n",
        "random_rows = df.sample(n=k, random_state=42)  # Set random_state for reproducibility\n",
        "\n",
        "x_test=random_rows\n",
        "x_test = x_test.reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.830108Z",
          "iopub.execute_input": "2025-02-18T01:28:46.830314Z",
          "iopub.status.idle": "2025-02-18T01:28:46.839993Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.830297Z",
          "shell.execute_reply": "2025-02-18T01:28:46.839353Z"
        },
        "id": "SnifHWTWseC_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x_test[:2]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.840811Z",
          "iopub.execute_input": "2025-02-18T01:28:46.841098Z",
          "iopub.status.idle": "2025-02-18T01:28:46.855364Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.841079Z",
          "shell.execute_reply": "2025-02-18T01:28:46.854674Z"
        },
        "id": "hK2c2bUHseC_",
        "outputId": "7e473fa4-3f47-4872-c21d-228db2cfb86a"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                            sentence     label language\n0  4-6 ವಯಸ್ಸಿನವರಿಗೆ ತುಂಬಾ ಭಾರವಾಗುತ್ತದೆ. ಮಕ್ಕಳು ಸ್...  Negative  Kannada\n1  ওরিও স্যান্ডউইচ বিস্কুটে ক্রিম ফিলিং এত সমৃদ্ধ...  Positive   Bangla",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentence</th>\n      <th>label</th>\n      <th>language</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4-6 ವಯಸ್ಸಿನವರಿಗೆ ತುಂಬಾ ಭಾರವಾಗುತ್ತದೆ. ಮಕ್ಕಳು ಸ್...</td>\n      <td>Negative</td>\n      <td>Kannada</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ওরিও স্যান্ডউইচ বিস্কুটে ক্রিম ফিলিং এত সমৃদ্ধ...</td>\n      <td>Positive</td>\n      <td>Bangla</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_prompt(data_point):\n",
        "    return f\"\"\"\n",
        "            Analyze the sentiment of the sentence which is in language {data_point[\"language\"]} enclosed in square brackets ,\n",
        "            determine if it is positive or negative, and return the answer as\n",
        "            the corresponding sentiment label \"Positive\" or \"Negative\".\n",
        "            [{data_point[\"sentence\"]}] = \"\"\".strip()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.856132Z",
          "iopub.execute_input": "2025-02-18T01:28:46.856443Z",
          "iopub.status.idle": "2025-02-18T01:28:46.867593Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.856384Z",
          "shell.execute_reply": "2025-02-18T01:28:46.866791Z"
        },
        "id": "Iw2HhvYRseC_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = x_test.label\n",
        "x_test = pd.DataFrame(x_test.apply(generate_test_prompt, axis=1), columns=[\"sentence\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.868353Z",
          "iopub.execute_input": "2025-02-18T01:28:46.86866Z",
          "iopub.status.idle": "2025-02-18T01:28:46.882249Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.868633Z",
          "shell.execute_reply": "2025-02-18T01:28:46.881478Z"
        },
        "id": "rBe2L1O7seC_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(y_true, y_pred):\n",
        "    labels = ['Positive', 'Negative']\n",
        "    mapping = {'Positive': 1, 'Negative': 0}\n",
        "    def map_func(x):\n",
        "        return mapping.get(x, 1)\n",
        "\n",
        "    y_true = np.vectorize(map_func)(y_true)\n",
        "    y_pred = np.vectorize(map_func)(y_pred)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
        "    print(f'Accuracy: {accuracy:.3f}')\n",
        "\n",
        "    # Calculate F1-score\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f'F1 Score: {f1:.3f}')\n",
        "\n",
        "    # Generate accuracy report\n",
        "    unique_labels = set(y_true)  # Get unique labels\n",
        "\n",
        "    for label in unique_labels:\n",
        "        label_indices = [i for i in range(len(y_true))\n",
        "                         if y_true[i] == label]\n",
        "        label_y_true = [y_true[i] for i in label_indices]\n",
        "        label_y_pred = [y_pred[i] for i in label_indices]\n",
        "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
        "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
        "\n",
        "    # Generate classification report\n",
        "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
        "    print('\\nClassification Report:')\n",
        "    print(class_report)\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])\n",
        "    print('\\nConfusion Matrix:')\n",
        "    print(conf_matrix)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:31:48.326507Z",
          "iopub.execute_input": "2025-02-18T01:31:48.326803Z",
          "iopub.status.idle": "2025-02-18T01:31:48.333525Z",
          "shell.execute_reply.started": "2025-02-18T01:31:48.326783Z",
          "shell.execute_reply": "2025-02-18T01:31:48.332636Z"
        },
        "id": "ge3Kf2bZseDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without Fine-Tuning"
      ],
      "metadata": {
        "id": "HpMp8Z70seDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "3NY-Y-kIseDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.895595Z",
          "iopub.execute_input": "2025-02-18T01:28:46.895822Z",
          "iopub.status.idle": "2025-02-18T01:28:46.906443Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.895805Z",
          "shell.execute_reply": "2025-02-18T01:28:46.905666Z"
        },
        "id": "_jbDgJ1YseDA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "compute_dtype = getattr(torch, \"float16\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "# Reload the model with quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=device,\n",
        "    torch_dtype=compute_dtype,\n",
        "    quantization_config=bnb_config,\n",
        ")\n",
        "print('compute dtype : ',compute_dtype)\n",
        "print(\"Model successfully quantized to 4-bit!\")\n",
        "print(10*'_',f\"Base Model size: {model.get_memory_footprint():,} bytes\\n\")\n",
        "\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:28:46.907153Z",
          "iopub.execute_input": "2025-02-18T01:28:46.907387Z",
          "iopub.status.idle": "2025-02-18T01:30:05.158923Z",
          "shell.execute_reply.started": "2025-02-18T01:28:46.907368Z",
          "shell.execute_reply": "2025-02-18T01:30:05.158266Z"
        },
        "id": "DtPeSk7wseDA",
        "outputId": "9652f085-ccf9-4e22-b2ca-295c9b09c6b5",
        "colab": {
          "referenced_widgets": [
            "833912b1a5a94e5ba446130538e36c69"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "833912b1a5a94e5ba446130538e36c69"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "compute dtype :  torch.float16\nModel successfully quantized to 4-bit!\n__________ Base Model size: 5,591,548,160 bytes\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer"
      ],
      "metadata": {
        "id": "_m1lDJctseDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "max_seq_length = 512\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,max_seq_length=max_seq_length)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:30:05.159619Z",
          "iopub.execute_input": "2025-02-18T01:30:05.159816Z",
          "iopub.status.idle": "2025-02-18T01:30:05.688037Z",
          "shell.execute_reply.started": "2025-02-18T01:30:05.159799Z",
          "shell.execute_reply": "2025-02-18T01:30:05.687388Z"
        },
        "id": "wl338hK1seDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate max token length\n",
        "def get_max_token_length(dataset):\n",
        "    max_length = 0\n",
        "    for sentence in dataset['sentence']:\n",
        "        tokenized = tokenizer(sentence)\n",
        "        max_length = max(max_length, len(tokenized['input_ids']))  # Length of tokenized sentence\n",
        "    return max_length\n",
        "\n",
        "# Calculate max token length for both train and validation datasets\n",
        "max_train_length = get_max_token_length(train_data)\n",
        "max_val_length = get_max_token_length(eval_data)\n",
        "\n",
        "print(max_train_length)\n",
        "print(max_val_length)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:30:05.688764Z",
          "iopub.execute_input": "2025-02-18T01:30:05.68897Z",
          "iopub.status.idle": "2025-02-18T01:30:06.099898Z",
          "shell.execute_reply.started": "2025-02-18T01:30:05.688953Z",
          "shell.execute_reply": "2025-02-18T01:30:06.099156Z"
        },
        "id": "q2mRGFPLseDB",
        "outputId": "fe2b9c54-3f5f-4b86-f91a-ec0f1bbe5b2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "807\n1106\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "def predict(x_test, model, tokenizer):\n",
        "    y_pred = []\n",
        "    for i in tqdm(range(len(x_test)),dynamic_ncols=True, desc=\"Processing\"):\n",
        "        if i == 0:  # Show this message only once, or suppress it entirely\n",
        "            sys.stdout.write(\"Device set to use cuda:0\\n\")\n",
        "        prompt = x_test.iloc[i][\"sentence\"]\n",
        "        pipe = pipeline(task=\"text-generation\",\n",
        "                        model=model,\n",
        "                        tokenizer=tokenizer,\n",
        "                        max_new_tokens = 1,\n",
        "                        temperature=0.1)\n",
        "        result = pipe(prompt)\n",
        "        answer = result[0]['generated_text'].split(\"=\")[-1]\n",
        "        if \"Positive\" in answer:\n",
        "            y_pred.append(\"Positive\")\n",
        "        elif \"Negative\" in answer:\n",
        "            y_pred.append(\"Negative\")\n",
        "        else:\n",
        "            y_pred.append(\"Positive\")\n",
        "    return y_pred"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:30:06.100619Z",
          "iopub.execute_input": "2025-02-18T01:30:06.100833Z",
          "iopub.status.idle": "2025-02-18T01:30:06.106168Z",
          "shell.execute_reply.started": "2025-02-18T01:30:06.100814Z",
          "shell.execute_reply": "2025-02-18T01:30:06.105334Z"
        },
        "id": "7FYhhlMfseDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict(x_test, model, tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Qn73QQbEseDB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(y_true, y_pred)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:32:10.727169Z",
          "iopub.execute_input": "2025-02-18T01:32:10.727517Z",
          "iopub.status.idle": "2025-02-18T01:32:10.744284Z",
          "shell.execute_reply.started": "2025-02-18T01:32:10.727492Z",
          "shell.execute_reply": "2025-02-18T01:32:10.743629Z"
        },
        "id": "LxbxHDGrseDC",
        "outputId": "73e44be0-7fbf-4243-db9b-dde0525444dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.750\nF1 Score: 0.809\nAccuracy for label 0: 0.564\nAccuracy for label 1: 0.869\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.73      0.56      0.64        39\n           1       0.76      0.87      0.81        61\n\n    accuracy                           0.75       100\n   macro avg       0.75      0.72      0.72       100\nweighted avg       0.75      0.75      0.74       100\n\n\nConfusion Matrix:\n[[22 17]\n [ 8 53]]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply LoRA for memory-efficient fine-tuning\n",
        "# lora_config = LoraConfig(\n",
        "#     r=16,\n",
        "#     lora_alpha=32,\n",
        "#     lora_dropout=0.05,\n",
        "#     bias=\"none\",\n",
        "#     target_modules=[\"q_proj\", \"v_proj\"]\n",
        "# )\n",
        "\n",
        "# model = get_peft_model(model, lora_config)\n",
        "# model.print_trainable_parameters()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:30:43.399729Z",
          "iopub.execute_input": "2025-02-18T01:30:43.399942Z",
          "iopub.status.idle": "2025-02-18T01:30:43.403068Z",
          "shell.execute_reply.started": "2025-02-18T01:30:43.399923Z",
          "shell.execute_reply": "2025-02-18T01:30:43.402285Z"
        },
        "id": "H9uqVl6nseDC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.DataFrame(test.apply(generate_test_prompt, axis=1), columns=[\"sentence\"])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:46:27.81265Z",
          "iopub.execute_input": "2025-02-18T01:46:27.812966Z",
          "iopub.status.idle": "2025-02-18T01:46:27.819069Z",
          "shell.execute_reply.started": "2025-02-18T01:46:27.812944Z",
          "shell.execute_reply": "2025-02-18T01:46:27.818121Z"
        },
        "id": "alR_bl7WseDC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test=predict(test, model, tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-18T01:42:41.457147Z",
          "iopub.execute_input": "2025-02-18T01:42:41.457501Z",
          "iopub.status.idle": "2025-02-18T01:43:21.475793Z",
          "shell.execute_reply.started": "2025-02-18T01:42:41.457475Z",
          "shell.execute_reply": "2025-02-18T01:43:21.474955Z"
        },
        "id": "OI1dBFkuseDC",
        "outputId": "90da8f93-8168-4542-f6ae-7341a44d14be"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Processing:   0%|          | 0/100 [00:00<?, ?it/s]Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Device set to use cuda:0\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Processing:   1%|          | 1/100 [00:00<00:30,  3.20it/s]Device set to use cuda:0\nProcessing:   2%|▏         | 2/100 [00:00<00:29,  3.34it/s]Device set to use cuda:0\nProcessing:   3%|▎         | 3/100 [00:00<00:27,  3.58it/s]Device set to use cuda:0\nProcessing:   4%|▍         | 4/100 [00:01<00:35,  2.74it/s]Device set to use cuda:0\nProcessing:   5%|▌         | 5/100 [00:01<00:34,  2.72it/s]Device set to use cuda:0\nProcessing:   6%|▌         | 6/100 [00:02<00:38,  2.45it/s]Device set to use cuda:0\nProcessing:   7%|▋         | 7/100 [00:02<00:33,  2.79it/s]Device set to use cuda:0\nProcessing:   8%|▊         | 8/100 [00:02<00:36,  2.51it/s]Device set to use cuda:0\nProcessing:   9%|▉         | 9/100 [00:03<00:35,  2.57it/s]Device set to use cuda:0\nProcessing:  10%|█         | 10/100 [00:03<00:33,  2.66it/s]Device set to use cuda:0\nProcessing:  11%|█         | 11/100 [00:04<00:36,  2.43it/s]Device set to use cuda:0\nProcessing:  12%|█▏        | 12/100 [00:04<00:35,  2.45it/s]Device set to use cuda:0\nProcessing:  13%|█▎        | 13/100 [00:04<00:32,  2.67it/s]Device set to use cuda:0\nProcessing:  14%|█▍        | 14/100 [00:05<00:30,  2.86it/s]Device set to use cuda:0\nProcessing:  15%|█▌        | 15/100 [00:05<00:27,  3.08it/s]Device set to use cuda:0\nProcessing:  16%|█▌        | 16/100 [00:05<00:32,  2.62it/s]Device set to use cuda:0\nProcessing:  17%|█▋        | 17/100 [00:06<00:34,  2.39it/s]Device set to use cuda:0\nProcessing:  18%|█▊        | 18/100 [00:06<00:31,  2.60it/s]Device set to use cuda:0\nProcessing:  19%|█▉        | 19/100 [00:07<00:37,  2.18it/s]Device set to use cuda:0\nProcessing:  20%|██        | 20/100 [00:07<00:32,  2.50it/s]Device set to use cuda:0\nProcessing:  21%|██        | 21/100 [00:07<00:28,  2.74it/s]Device set to use cuda:0\nProcessing:  22%|██▏       | 22/100 [00:08<00:26,  2.98it/s]Device set to use cuda:0\nProcessing:  23%|██▎       | 23/100 [00:08<00:24,  3.19it/s]Device set to use cuda:0\nProcessing:  24%|██▍       | 24/100 [00:08<00:28,  2.68it/s]Device set to use cuda:0\nProcessing:  25%|██▌       | 25/100 [00:09<00:28,  2.62it/s]Device set to use cuda:0\nProcessing:  26%|██▌       | 26/100 [00:09<00:28,  2.57it/s]Device set to use cuda:0\nProcessing:  27%|██▋       | 27/100 [00:10<00:28,  2.60it/s]Device set to use cuda:0\nProcessing:  28%|██▊       | 28/100 [00:10<00:33,  2.17it/s]Device set to use cuda:0\nProcessing:  29%|██▉       | 29/100 [00:11<00:29,  2.41it/s]Device set to use cuda:0\nProcessing:  30%|███       | 30/100 [00:11<00:29,  2.37it/s]Device set to use cuda:0\nProcessing:  31%|███       | 31/100 [00:11<00:26,  2.60it/s]Device set to use cuda:0\nProcessing:  32%|███▏      | 32/100 [00:12<00:27,  2.49it/s]Device set to use cuda:0\nProcessing:  33%|███▎      | 33/100 [00:12<00:27,  2.45it/s]Device set to use cuda:0\nProcessing:  34%|███▍      | 34/100 [00:13<00:25,  2.64it/s]Device set to use cuda:0\nProcessing:  35%|███▌      | 35/100 [00:13<00:23,  2.80it/s]Device set to use cuda:0\nProcessing:  36%|███▌      | 36/100 [00:13<00:21,  3.03it/s]Device set to use cuda:0\nProcessing:  37%|███▋      | 37/100 [00:13<00:21,  2.92it/s]Device set to use cuda:0\nProcessing:  38%|███▊      | 38/100 [00:14<00:19,  3.10it/s]Device set to use cuda:0\nProcessing:  39%|███▉      | 39/100 [00:14<00:19,  3.19it/s]Device set to use cuda:0\nProcessing:  40%|████      | 40/100 [00:15<00:22,  2.62it/s]Device set to use cuda:0\nProcessing:  41%|████      | 41/100 [00:15<00:21,  2.80it/s]Device set to use cuda:0\nProcessing:  42%|████▏     | 42/100 [00:15<00:21,  2.75it/s]Device set to use cuda:0\nProcessing:  43%|████▎     | 43/100 [00:16<00:19,  2.86it/s]Device set to use cuda:0\nProcessing:  44%|████▍     | 44/100 [00:16<00:23,  2.34it/s]Device set to use cuda:0\nProcessing:  45%|████▌     | 45/100 [00:16<00:21,  2.56it/s]Device set to use cuda:0\nProcessing:  46%|████▌     | 46/100 [00:17<00:19,  2.80it/s]Device set to use cuda:0\nProcessing:  47%|████▋     | 47/100 [00:17<00:17,  3.01it/s]Device set to use cuda:0\nProcessing:  48%|████▊     | 48/100 [00:18<00:20,  2.50it/s]Device set to use cuda:0\nProcessing:  49%|████▉     | 49/100 [00:18<00:18,  2.70it/s]Device set to use cuda:0\nProcessing:  50%|█████     | 50/100 [00:18<00:18,  2.65it/s]Device set to use cuda:0\nProcessing:  51%|█████     | 51/100 [00:19<00:17,  2.88it/s]Device set to use cuda:0\nProcessing:  52%|█████▏    | 52/100 [00:19<00:16,  2.98it/s]Device set to use cuda:0\nProcessing:  53%|█████▎    | 53/100 [00:19<00:15,  3.07it/s]Device set to use cuda:0\nProcessing:  54%|█████▍    | 54/100 [00:20<00:16,  2.82it/s]Device set to use cuda:0\nProcessing:  55%|█████▌    | 55/100 [00:20<00:16,  2.70it/s]Device set to use cuda:0\nProcessing:  56%|█████▌    | 56/100 [00:20<00:15,  2.80it/s]Device set to use cuda:0\nProcessing:  57%|█████▋    | 57/100 [00:21<00:14,  2.99it/s]Device set to use cuda:0\nProcessing:  58%|█████▊    | 58/100 [00:21<00:15,  2.74it/s]Device set to use cuda:0\nProcessing:  59%|█████▉    | 59/100 [00:21<00:13,  2.94it/s]Device set to use cuda:0\nProcessing:  60%|██████    | 60/100 [00:22<00:14,  2.78it/s]Device set to use cuda:0\nProcessing:  61%|██████    | 61/100 [00:22<00:13,  3.00it/s]Device set to use cuda:0\nProcessing:  62%|██████▏   | 62/100 [00:22<00:11,  3.17it/s]Device set to use cuda:0\nProcessing:  63%|██████▎   | 63/100 [00:23<00:11,  3.26it/s]Device set to use cuda:0\nProcessing:  64%|██████▍   | 64/100 [00:23<00:13,  2.61it/s]Device set to use cuda:0\nProcessing:  65%|██████▌   | 65/100 [00:24<00:16,  2.18it/s]Device set to use cuda:0\nProcessing:  66%|██████▌   | 66/100 [00:24<00:14,  2.41it/s]Device set to use cuda:0\nProcessing:  67%|██████▋   | 67/100 [00:24<00:13,  2.47it/s]Device set to use cuda:0\nProcessing:  68%|██████▊   | 68/100 [00:25<00:15,  2.11it/s]Device set to use cuda:0\nProcessing:  69%|██████▉   | 69/100 [00:26<00:14,  2.12it/s]Device set to use cuda:0\nProcessing:  70%|███████   | 70/100 [00:26<00:16,  1.78it/s]Device set to use cuda:0\nProcessing:  71%|███████   | 71/100 [00:27<00:13,  2.09it/s]Device set to use cuda:0\nProcessing:  72%|███████▏  | 72/100 [00:27<00:14,  1.96it/s]Device set to use cuda:0\nProcessing:  73%|███████▎  | 73/100 [00:27<00:12,  2.24it/s]Device set to use cuda:0\nProcessing:  74%|███████▍  | 74/100 [00:28<00:11,  2.32it/s]Device set to use cuda:0\nProcessing:  75%|███████▌  | 75/100 [00:28<00:11,  2.26it/s]Device set to use cuda:0\nProcessing:  76%|███████▌  | 76/100 [00:29<00:11,  2.07it/s]Device set to use cuda:0\nProcessing:  77%|███████▋  | 77/100 [00:29<00:10,  2.10it/s]Device set to use cuda:0\nProcessing:  78%|███████▊  | 78/100 [00:30<00:09,  2.29it/s]Device set to use cuda:0\nProcessing:  79%|███████▉  | 79/100 [00:30<00:09,  2.26it/s]Device set to use cuda:0\nProcessing:  80%|████████  | 80/100 [00:31<00:11,  1.80it/s]Device set to use cuda:0\nProcessing:  81%|████████  | 81/100 [00:31<00:09,  2.02it/s]Device set to use cuda:0\nProcessing:  82%|████████▏ | 82/100 [00:32<00:08,  2.23it/s]Device set to use cuda:0\nProcessing:  83%|████████▎ | 83/100 [00:32<00:07,  2.26it/s]Device set to use cuda:0\nProcessing:  84%|████████▍ | 84/100 [00:33<00:06,  2.30it/s]Device set to use cuda:0\nProcessing:  85%|████████▌ | 85/100 [00:33<00:05,  2.53it/s]Device set to use cuda:0\nProcessing:  86%|████████▌ | 86/100 [00:33<00:05,  2.67it/s]Device set to use cuda:0\nProcessing:  87%|████████▋ | 87/100 [00:34<00:05,  2.46it/s]Device set to use cuda:0\nProcessing:  88%|████████▊ | 88/100 [00:34<00:04,  2.66it/s]Device set to use cuda:0\nProcessing:  89%|████████▉ | 89/100 [00:34<00:04,  2.59it/s]Device set to use cuda:0\nProcessing:  90%|█████████ | 90/100 [00:35<00:04,  2.14it/s]Device set to use cuda:0\nProcessing:  91%|█████████ | 91/100 [00:35<00:03,  2.35it/s]Device set to use cuda:0\nProcessing:  92%|█████████▏| 92/100 [00:36<00:03,  2.52it/s]Device set to use cuda:0\nProcessing:  93%|█████████▎| 93/100 [00:36<00:02,  2.43it/s]Device set to use cuda:0\nProcessing:  94%|█████████▍| 94/100 [00:37<00:02,  2.15it/s]Device set to use cuda:0\nProcessing:  95%|█████████▌| 95/100 [00:37<00:02,  2.32it/s]Device set to use cuda:0\nProcessing:  96%|█████████▌| 96/100 [00:38<00:01,  2.30it/s]Device set to use cuda:0\nProcessing:  97%|█████████▋| 97/100 [00:38<00:01,  2.45it/s]Device set to use cuda:0\nProcessing:  98%|█████████▊| 98/100 [00:39<00:01,  1.99it/s]Device set to use cuda:0\nProcessing:  99%|█████████▉| 99/100 [00:39<00:00,  1.91it/s]Device set to use cuda:0\nProcessing: 100%|██████████| 100/100 [00:40<00:00,  2.50it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_ids = pd.read_csv(\"/kaggle/input/multi-lingual-sentiment-analysis/test.csv\")[\"ID\"]\n",
        "# Create submission file with index\n",
        "submission_df = pd.DataFrame({'ID': test_ids, 'label': y_pred_test})\n",
        "\n",
        "# Save as CSV\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "id": "oXDyAj4DseDC"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}